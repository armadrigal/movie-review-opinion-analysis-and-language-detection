{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d088c99",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5cb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (Embedding, Bidirectional, LSTM, \n",
    "    Dense, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten, \n",
    "    Attention, MultiHeadAttention, Input, GRU, Concatenate)\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.metrics import Accuracy, Recall, Precision\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from nltk import FreqDist\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f56cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e072dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review_fr', 'sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72fa054",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_texts(texts):\n",
    "    clean_texts = []\n",
    "    for text in texts:\n",
    "        text = re.sub(r'[^a-zA-Záéíóúüñàâäéèêëîïôœùûç\\']', ' ', text)\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        clean_texts.append(text)\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(texts):\n",
    "    tokenized_texts = []\n",
    "    for text in texts:\n",
    "        tokenized_texts.append(text.split())\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452bde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    texts_without_stopwords = []\n",
    "    nltk.download(\"stopwords\")\n",
    "    stop_words = set(stopwords.words(\"portuguese\"))\n",
    "    for text in texts:\n",
    "        texts_without_stopwords.append([word for word in text if word not in stop_words])\n",
    "    return texts_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe907c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(texts, vocabulary):\n",
    "    vectoriced_texts = []\n",
    "    for i, text in enumerate(texts):\n",
    "        vectoriced_text = []\n",
    "        for j, word in enumerate(text):\n",
    "            if word in vocabulary:\n",
    "                vectoriced_text.append(vocabulary[word]) \n",
    "            else:\n",
    "                vectoriced_text.append(0) \n",
    "        vectoriced_texts.append(vectoriced_text)\n",
    "    return vectoriced_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2557c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['review_pt'].to_list()\n",
    "clean_texts = cleaning_texts(texts)\n",
    "tokenized_texts = tokenize_texts(clean_texts)\n",
    "tokenized_texts = remove_stopwords(tokenized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fbf042",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ' '.join(' '.join(text) for text in tokenized_texts)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='black').generate(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69350158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fc092",
   "metadata": {},
   "source": [
    "## Top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in tokenized_texts:\n",
    "    words.extend(text)\n",
    "frequency = FreqDist(words)\n",
    "top_20 = frequency.most_common(20)\n",
    "words, freq = zip(*top_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d608f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(words, freq)\n",
    "plt.xlabel('Frecuencia')\n",
    "plt.ylabel('Palabras')\n",
    "plt.title('Top 20 Palabras en el Conjunto de Textos')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631900c",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = Word2Vec(tokenized_texts, vector_size=50, window=10, min_count=10, workers=4)\n",
    "model_word2vec.train(tokenized_texts,total_examples=model_word2vec.corpus_count, epochs=20)\n",
    "model_word2vec.save(\"./API/Models/Word2Vec_pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d7024",
   "metadata": {},
   "source": [
    "## Vectorize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = Word2Vec.load(\"./API/Models/Word2Vec_pt\")\n",
    "vocabulary = model_word2vec.wv.key_to_index\n",
    "with open(\"./API/vocabulary/vocabulary_pt\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f672f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 150\n",
    "max_words = len(vocabulary)\n",
    "\n",
    "vectorized_texts = vectorize_texts(tokenized_texts, vocabulary)\n",
    "X = pad_sequences(vectorized_texts, maxlen=maxlen)\n",
    "y = df['sentiment'].apply(lambda x : 1 if x == 'positive' else 0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a678b15",
   "metadata": {},
   "source": [
    "## Split dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1243133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc5264",
   "metadata": {},
   "source": [
    "## Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad46b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_words, 50))\n",
    "for word, i in vocabulary.items():\n",
    "    if i < max_words:\n",
    "        if word in vocabulary:\n",
    "            embedding_matrix[i] = model_word2vec.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4815ff0",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b42a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.8)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='large')\n",
    " \n",
    "    plt.xlabel('Predictions', fontsize=12)\n",
    "    plt.ylabel('Actuals', fontsize=12)\n",
    "    plt.title('Confusion Matrix', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919cb78",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Input(shape=(maxlen,)))\n",
    "model_lstm.add(Embedding(input_dim=max_words, output_dim=50, weights=[embedding_matrix], trainable=False))\n",
    "model_lstm.add(Bidirectional(LSTM(64, return_sequences=True)))  \n",
    "model_lstm.add(Bidirectional(LSTM(64, return_sequences=True))) \n",
    "model_lstm.add(Flatten())\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Recall(), Precision()]\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    './API/Models/model_lstm_fr.h5', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max', \n",
    "    verbose=0\n",
    ")  \n",
    "\n",
    "model_lstm_history = model_lstm.fit(\n",
    "    X_train, y_train, validation_split=0.2, \n",
    "    epochs=10, batch_size=128, callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4406bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = load_model(\"./API/Models/model_lstm_fr.h5\")\n",
    "y_pred_lstm = np.round(model_lstm.predict(X_test).T).astype(int)[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862556cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7a2c2",
   "metadata": {},
   "source": [
    "## Bidirectional GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd025c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(Input(shape=(maxlen,)))\n",
    "model_gru.add(Embedding(input_dim=max_words, output_dim=50, weights=[embedding_matrix], trainable=False))\n",
    "model_gru.add(GRU(64, return_sequences=True))  \n",
    "model_gru.add(GRU(64, return_sequences=True)) \n",
    "model_gru.add(Flatten())\n",
    "model_gru.add(Dense(64, activation='relu'))\n",
    "model_gru.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Recall(), Precision()]\n",
    ")\n",
    "\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    './API/Models/model_gru_fr.h5', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max', \n",
    "    verbose=0\n",
    ")  \n",
    "\n",
    "model_gru_history = model_gru.fit(\n",
    "    X_train, y_train, validation_split=0.2, \n",
    "    epochs=10, batch_size=128, callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = load_model(\"./API/Models/model_gru_fr.h5\")\n",
    "y_pred_gru = np.round(model_gru.predict(X_test).T).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_gru))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fdd1a",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf162e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Input(shape=(maxlen,)))\n",
    "model_cnn.add(Embedding(input_dim=max_words, output_dim=50, weights=[embedding_matrix], trainable=False))\n",
    "model_cnn.add(Conv1D(256, kernel_size=8, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Conv1D(64, kernel_size=4, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Recall(), Precision()]\n",
    ")\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf07b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    './API/Models/model_cnn_fr.h5', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max', \n",
    "    verbose=0\n",
    ")  \n",
    "\n",
    "model_cnn_history = model_cnn.fit(\n",
    "    X_train, y_train, validation_split=0.2, \n",
    "    epochs=10, batch_size=128, callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = load_model(\"./API/Models/model_cnn_fr.h5\")\n",
    "y_pred_cnn = np.round(model_cnn.predict(X_test).T).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c728eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6802a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8097f",
   "metadata": {},
   "source": [
    "## Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(maxlen,))\n",
    "x = Embedding(input_dim=max_words, output_dim=50, weights=[embedding_matrix], trainable=False)(inputs)\n",
    "x = MultiHeadAttention(num_heads=16, key_dim=16, value_dim=16)(x, x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = MultiHeadAttention(num_heads=8, key_dim=16, value_dim=16)(x, x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dense(units=1, activation='sigmoid')(x)\n",
    "model_attention = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad44b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attention.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Recall(), Precision()]\n",
    ")\n",
    "model_attention.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fe1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    './API/Models/model_attention_fr.h5', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max', \n",
    "    verbose=0\n",
    ")  \n",
    "\n",
    "model_attention_history = model_attention.fit(\n",
    "    X_train, y_train, validation_split=0.2, \n",
    "    epochs=10, batch_size=128, callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attention = load_model(\"./API/Models/model_attention_fr.h5\")\n",
    "y_pred_attention = np.round(model_attention.predict(X_test).T).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53299c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_attention))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e8e1a",
   "metadata": {},
   "source": [
    "## LSTM+Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a638d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(maxlen,))\n",
    "x = Embedding(input_dim=max_words, output_dim=50, weights=[embedding_matrix], trainable=False)(inputs)\n",
    "lstm_1 = Bidirectional(LSTM(units=64, return_sequences=True))(x)\n",
    "lstm_2 = Bidirectional(LSTM(units=64, return_sequences=True))(x)\n",
    "x = MultiHeadAttention(num_heads=8, key_dim=16, value_dim=16)(lstm_1, lstm_2)\n",
    "x = MultiHeadAttention(num_heads=4, key_dim=16, value_dim=16)(x, x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dense(units=1, activation='sigmoid')(x)\n",
    "model_lstm_attention = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_attention.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Recall(), Precision()]\n",
    ")\n",
    "model_lstm_attention.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    './API/Models/model_lstm_attention_fr.h5', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max', \n",
    "    verbose=0\n",
    ")  \n",
    "\n",
    "model_lstm_attention_history = model_lstm_attention.fit(\n",
    "    X_train, y_train, validation_split=0.2, \n",
    "    epochs=10, batch_size=128, callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_attention = load_model(\"./API/Models/model_lstm_attention_fr.h5\")\n",
    "y_pred_lstm_attention = np.round(model_lstm_attention.predict(X_test).T).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34177cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_lstm_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69092d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_lstm_attention))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
